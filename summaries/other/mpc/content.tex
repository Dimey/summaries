\chapter{Introduction}
    This summary covers \emph{model predictive control} (MPC) combined with \emph{machine learning} (ML). In MPC, a model of a dynamical system is used to find inputs that steer the system optimally (in some sense). ML, on the other hand, can be used to build such models from data. This document focuses primarily on the MPC part, featuring nominal, robust, and stochastic MPC. Subsequently, connections to and applications of ML are drawn as these fields get more and more interconnected. The key topics are understanding MPC basics, identifying benefits and drawbacks of MPC, understanding the role of ML in control, understanding the basic concepts of ML-supported MPC as well as its benefits and drawbacks.

    \section{What is Model Predictive Control?}
        In general, \emph{control} is concerned with influencing a dynamical system such that it exhibits a wanted behavior. Usually, this involves incorporating feedback (e.g., the actual state of the system) into the control law (feedback control). In \emph{optimal} control, the inputs shall be optimal in some sense (e.g., minimal energy consumption, avoidance of states, \dots).

        In \emph{model} predictive control, a model of the system is used to predict the influence of inputs. This has the advantage of the controller actually understanding what it is doing, potentially increasing the performance and yielding a structured design process of the controller. On the other hand, MPC needs a model that can be hard to obtain\footnote{A common way to obtain a model aside from deriving it using first principles are gathering data of the system, fixing a model structure, and fitting the parameters.}. Also, it is computationally expensive and its  performance is highly influenced by the model quality and accuracy.

        An MPC controller performs \emph{prediction} using the model to assess the influence of certain actions. This can be used for finding the optimal inputs by minimizing a cost function on the predicted states. This optimal input can then be applied to the system. Hence, MPC is \emph{optimization-based} control: the optimal input is retrieved by minimizing a cost function with the dynamical system as a constraint on the states. This allows to incorporate additional constraints (e.g., min/max actions or unsafe states) directly into the optimizer. To incorporate feedback from the actual system, this optimization problem is solved repeatedly during execution (see \autoref{fig:mpcCycle}).

        Model predictive control is covered in detail in \autoref{c:mpcNominal}, \ref{c:mpcRobust}, and \ref{c:mpcStochastic}.

        \begin{figure}
        	\centering
        	\begin{tikzpicture}[->, every node/.style = { draw, rectangle, minimum width = 3cm, minimum height = 1cm }]
        		\node (a) {Obtain State};
        		\node [right = 1.5 of a] (b) {Predict System};
        		\draw (a) to coordinate(d) (b);
        		\node [below = 1 of d] (c) {Apply Input};
        		\draw (b) |- (c);
        		\draw (c) -| (a);
        	\end{tikzpicture}
        	\caption{Illustration of the model predictive control cycle.}
        	\label{fig:mpcCycle}
        \end{figure}
    % end

    \section{What is Machine Learning?}
       	While there is no unified definition of machine learning, it is often used to describe systems that use a bunch of data to find relations/patterns/connections/\dots in them and to extract general rules. Typical methods are neural networks, Gaussian processes, support vector machines, and many more. In control, the applications of machine learning are twofold: first, it can be used to find a model and use the model in a model-based controller (supervised learning and regression); second, this step can also be skipped and ML can be applied directly as the controller (usually covered in reinforcement learning).

       	Machine learning for MPC is covered in detail in \autoref{c:ml}.
    % end
% end

\chapter{Preliminaries} % N/A
    \todo{Content}

    \section{System Theory} % 2.1, 2.3, 2.36
        \todo{Content}

        \subsection{Types of Dynamical Systems} % 2.4, 2.15
            \todo{Content}

            \subsubsection{Time-Continous} % 2.5, 2.6, 2.8, 2.9
                \todo{Content}

                \paragraph{Linearization} % 2.7
                    \todo{Content}
                % end
            % end

            \subsubsection{Time-Discrete} % 2.12, 2.13, 2.14
                \todo{Content}

                \paragraph{Discretization} % 2.10, 2.11
                    \todo{Content}
                % end
            % end
        % end

        \subsection{Stability} % 2.16, 2.17, 2.29, 12.4
            \todo{Content}

            \subsubsection{State-Feedback Controllers} % 2.18
                \todo{Content}
            % end

            \subsubsection{Lyapunov Stability} % 2.19
                \todo{Content}
            % end

            \subsubsection{Asymptotic Stability} % 2.20
                \todo{Content}
            % end

            \subsubsection{Lyapunov Functions} % 2.21, 2.22, 2.23, 2.24, 2.25, 2.26, 2.27, 2.28, 12.5
                \todo{Content}
            % end
        % end

        \subsection{Detectability, Observability, Controllability, and Stabilizability} % 2.30, 2.31, 2.32, 3.3, 3.4
            \todo{Content}
        % end

        \subsection{Outlook} % 2.33, 2.34, 2.35
            \todo{Content}
        % end
    % end

    \section{Linear Quadratic Regulator} % 3.1, 3.2, 3.5, 3.6, 3.7, 3.8, 3.10, 3.11, 3.13, 3.35, 12.6, 12.7
        \todo{Content}

        \subsection{Cost Functions} % 3.14, 3.15, 3.16, 3.17
            \todo{Content}
        % end

        \subsection{LQR Formulation} % 3.18, 3.19, 3.20
            \todo{Content}
        % end

        \subsection{Batch Optimization} % 3.21, 3.22, 3.23, 3.24
            \todo{Content}
        % end

        \subsection{Dynamic Programming} % 3.25
            \todo{Content}

            \subsubsection{Optimal Cost-to-Go} % 3.26
                \todo{Content}
            % end

            \subsubsection{Recursive Solution} % 3.27, 3.28, 3.29
                \todo{Content}
            % end

            \subsubsection{Infinite Horizon} % 3.30, 3.31
                \todo{Content}
            % end
        % end

        \subsection{Stability} % 3.32, 3.33, 12.8
            \todo{Content}
        % end

        \subsection{Outlook} % 3.36
            \todo{Content}
        % end
    % end

    \section{Constrained Optimization} % 4.1, 4.2, 4.3, 4.4, 4.28, 12.9
        \todo{Content}

        \subsection{Nomenclature} % 4.5, 4.6, 4.7, 4.8
            \todo{Content}
        % end

        \subsection{Global and Local Optimality} % 4.9
            \todo{Content}
        % end

        \subsection{Convexity} % N/A
            \todo{Content}

            \subsubsection{Convex Sets} % 4.10, 4.11, 4.12, 4.13
                \todo{Content}
            % end

            \subsubsection{Convex Functions} % 4.14, 4.15
                \todo{Content}
            % end

            \subsubsection{(Sub-) Level Sets} % 4.16
                \todo{Content}
            % end

            \subsubsection{Convex Optimization Problems and Optimality} % 4.18, 4.19
                \todo{Content}
            % end
        % end

        \subsection{Quadratic Programming} % 4.20, 4.21
            \todo{Content}
        % end

        \subsection{Optimality Conditions for Constraints Optimization Problems} % 4.22
            \todo{Content}

            \subsubsection{Lagrangian} % 4.23, 4.24
                \todo{Content}
            % end

            \subsubsection{Generalized Lagrangian and KKT-Conditions} % 4.25, 4.26
                \todo{Content}
            % end
        % end

        \subsection{Numerical Solver} % 6.23, 6.24, 6.25, 6.30
            \todo{Content}

            \subsubsection{Penalty Functions} % 6.26, 6.27, 6.28, 6.29
                \todo{Content}
            % end

            \subsubsection{Soft Constraints} % 6.31, 6.32
                \todo{Content}
            % end
        % end
    % end
% end

\chapter{Nominal Model Predictive Control} % 5.1, 5.2, 5.3, 5.4, 5.5, 5.38, 12.10
	\label{c:mpcNominal}

    \todo{Content}

    \section{Receding Horizon} % 5.6, 5.7, 5.8, 5.9, 5.10, 5.11
        \todo{Content}
    % end

    \section{Nominal MPC} % 5.12, 5.13
        \todo{Content}
    % end

    \section{Linear MPC} % 5.14, 5.15
        \todo{Content}
    % end

    \section{Recursive Feasibility and Stability} % 5.16, 5.17, 5.18, 5.19, 5.20, 5.21, 12.11
        \todo{Content}

        \subsection{\dots using a Terminal Equality} % 5.22
            \todo{Content}

            \subsubsection{Achieving Recursive Feasibility} % 5.23, 5.24
                \todo{Content}
            % end

            \subsubsection{Achieving Stability} % 5.25, 5.26, 5.27
                \todo{Content}
            % end
        % end

        \subsection{\dots using a Terminal Set} % 5.28, 5.29
            \todo{Content}

            \subsubsection{Invariant Sets} % 5.30, 5.31
                \todo{Content}
            % end

            \subsubsection{Stability of MPC} % 5.32, 5.37, 6.10
                \todo{Content}
            % end

            \subsubsection{Showing Recursive Feasibility} % 5.33, 5.34
                \todo{Content}
            % end

            \subsubsection{Showing Stability} % 5.35, 5.36, 6.8, 6.9
                \todo{Content}
            % end
        % end
    % end

    \section{Solving MPC Problem} % 6.11, 6.12, 6.33, 12.12
        \todo{Content}

        \subsection{Reformulation Linear MPC as a QP} % 6.13, 6.22
            \todo{Content}

            \subsubsection{\dots with Substitution} % 6.14, 6.15, 6.16, 6.17
                \todo{Content}
            % end

            \subsubsection{\dots without Substitution} % 6.18, 6.19, 6.20, 6.21
                \todo{Content}
            % end
        % end
    % end
% end

\chapter{Robust Model Predictive Control} % 7.1, 7.3, 7.20, 7.32, 12.13, 12.14
	\label{c:mpcRobust}

    \todo{Content}

    \section{Inherent Robustness of Nominal MPC} % 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 7.10, 7.11
        \todo{Content}
    % end

    \section{Uncertain Models} % 7.12, 7.13, 7.14
        \todo{Content}

        \subsection{System Evolution} % 7.15, 7.16
            \todo{Content}
        % end
    % end

    \section{Cost Functions for Uncertain Systems} % 7.17, 7.18
        \todo{Content}
    % end

    \section{Minimax MPC} % 7.19
        \todo{Content}
    % end

    \section{Set Subtraction and Addition} % 7.21, 7.22, 7.23
        \todo{Content}
    % end

    \section{Robust Open-Loop MPC} % 7.24, 7.25, 7.26
        \todo{Content}
    % end

    \section{Tube MPC} % 7.27, 7.28, 7.29, 7.30, 7.31
        \todo{Content}
    % end
% end

\chapter{Stochastic Model Predictive Control} % 8.1, 8.8, 8.13, 8.22, 12.13, 12.15
	\label{c:mpcStochastic}

    \todo{Content}

    \section{Stochastic Uncertainty} % 8.9, 8.10, 8.11
        \todo{Content}
    % end

    \section{Uncertain System Evolution} % 8.12
        \todo{Content}
    % end

    \section{Chance Constraints} % 8.14, 8.15, 8.16, 8.17
        \todo{Content}
    % end

    \section{Stochastic Tube MPC} % 8.18, 8.19
        \todo{Content}
    % end

    \section{Outlook} % 8.20, 8.21
        \todo{Content}
    % end
% end

\chapter{Machine Learning in Model Predictive Control} % 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9, 9.10, 9.12, 12.16, 12.17
	\label{c:ml}

    \todo{Content}

    \section{Machine Learning for MPC} % 9.11, 9.13, 10.8
        \todo{Content}

        \subsection{Modeling Dynamical Systems with ML} % 9.14
            \todo{Content}

            \subsubsection{Implications} % 9.15, 9.16, 9.19
                \todo{Content}

                \paragraph{Safe Sets} % 9.17
                    \todo{Content}
                % end

                \paragraph{Robust Learning Supported Tube MPC} % 9.18
                    \todo{Content}
                % end
            % end
        % end

        \subsection{Modeling External Signals} % 10.3, 10.4
            \todo{Content}
        % end

        \subsection{Modeling Constraints} % 10.5
            \todo{Content}
        % end

        \subsection{Modeling Cost Functions} % 10.6
            \todo{Content}
        % end

        \subsection{Learning Control Input: Replacing MPC} % 10.7
            \todo{Content}
        % end
    % end

    \section{Gaussian Processes} % 10.1, 10.9, 10.35, 12.18
        \todo{Content}

        \subsection{Setup and Definition} % 10.10, 10.17, 10.18, 10.19
            \todo{Content}
        % end

        \subsection{GP Regression} % 10.20
            \todo{Content}

            \subsubsection{Prior Distribution} % 10.21, 10.26
                \todo{Content}

                \paragraph{Mean Function} % 10.22, 10.37, 10.38, 10.39
                    \todo{Content}
                % end

                \paragraph{Covariance Function} % 10.23, 10.24, 10.25, 10.40, 10.49, 10.50
                    \todo{Content}
                % end
            % end

            \subsubsection{Posterior Distribution} % 10.27, 10.28
                \todo{Content}
            % end

            \subsubsection{Noise Observations} % 10.51, 10.52
                \todo{Content}
            % end
        % end

        \subsection{Hyper-Parameter Learning} % 10.29
            \todo{Content}

            \subsubsection{Influence of the Hyper-Parameters} % 10.41, 10.42, 10.43, 10.44, 10.45, 10.46, 10.47
                \todo{Content}
            % end

            \subsubsection{Automatic Relevance Determination} % 10.48
                \todo{Content}
            % end
        % end

        \subsection{Dynamic Process Models} % 10.32, 10.33
            \todo{Content}
        % end

        \subsection{Benefits and Drawbacks} % 10.30, 10.31
            \todo{Content}
        % end
    % end

    \section{(Artificial) Neural Networks} % 11.1, 11.3, 11.25, 12.19
        \todo{Content}

        \subsection{Setup} % 11.4, 11.6, 11.7, 11.8
            \todo{Content}
        % end

        \subsection{Signal Direction} % 11.9, 11.10, 11.11
            \todo{Content}
        % end

        \subsection{Connections Between Nodes} % 11.12
            \todo{Content}
        % end

        \subsection{Activation Functions} % 11.13
            \todo{Content}
        % end

        \subsection{Training} % 11.14, 11.15, 11.16, 11.17
            \todo{Content}

            \subsubsection{Optimization Algorithm} % 11.18
                \todo{Content}
            % end

            \subsubsection{Challenges} % 11.19, 11.20
                \todo{Content}
            % end
        % end

        \subsection{Neural Networks in MPOC} % 11.24
            \todo{Content}
        % end

        \subsection{Benefits and Drawbacks} % 11.23
            \todo{Content}
        % end
    % end

    \section{Remarks on Nomenclature} % 11.21
        \todo{Content}
    % end
% end

\chapter{Outlook} % 13.1, 13.6, 13.10
    \todo{Content}

    \section{Libraries for Machine Learning} % 13.3, 13.4, 13.5
        \todo{Content}
    % end

    \section{Reinforcement Learning vs. MPC} % 13.7, 13.8, 13.9
        \todo{Content}
    % end
% end
